import OpenAI from 'openai';
import { config } from '../config/environment';
import { UserRepository } from '../repositories/UserRepository';
import { ProfileRepository } from '../repositories/ProfileRepository';
import { ShuffleResponseRepository } from '../repositories/QuestionRepository';
import { KnowledgeExtractor } from './KnowledgeExtractor';
import { ContextBuilder } from './ContextBuilder';
import { logger } from '../utils/logger';

export interface AIQuery {
  query: string;
  userId: string;
  channelId?: string;
  context?: string;
}

export interface AIResponse {
  response: string;
  confidence: number;
  sources?: string[];
  suggestedActions?: string[];
}

export interface KnowledgeContext {
  profiles: any[];
  recentResponses: any[];
  users: any[];
}

export class AIDialogueService {
  private openai: OpenAI;
  private userRepository: UserRepository;
  private profileRepository: ProfileRepository;
  private shuffleResponseRepository: ShuffleResponseRepository;
  private knowledgeExtractor: KnowledgeExtractor;
  private contextBuilder: ContextBuilder;

  constructor() {
    this.openai = new OpenAI({
      apiKey: config.openai.apiKey,
    });
    this.userRepository = new UserRepository();
    this.profileRepository = new ProfileRepository();
    this.shuffleResponseRepository = new ShuffleResponseRepository();
    this.knowledgeExtractor = new KnowledgeExtractor();
    this.contextBuilder = new ContextBuilder();
  }

  async processQuery(query: AIQuery): Promise<AIResponse> {
    try {
      logger.info('Processing AI query', {
        userId: query.userId,
        queryLength: query.query.length
      });

      // Build comprehensive AI context using ContextBuilder
      const aiContext = await this.contextBuilder.buildAIContext(query.userId, query.query);
      
      // Generate enhanced system prompt with rich context
      const systemPrompt = this.buildEnhancedSystemPrompt(aiContext);
      
      // Build knowledge context for the query
      const knowledgeContext = this.buildKnowledgeContextFromAI(aiContext);
      
      // Process the query with OpenAI
      const completion = await this.openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: query.query
          }
        ],
        max_tokens: 500,
        temperature: 0.7,
      });

      const response = completion.choices[0]?.message?.content || 'ã™ã¿ã¾ã›ã‚“ã€å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚';
      
      // Extract confidence and suggestions using enhanced context
      const aiResponse = this.parseEnhancedAIResponse(response, aiContext);
      
      logger.info('AI query processed successfully', {
        userId: query.userId,
        responseLength: aiResponse.response.length,
        confidence: aiResponse.confidence,
        queryType: aiContext.conversationContext.queryType
      });

      return aiResponse;
    } catch (error) {
      logger.error('Error processing AI query:', error);
      
      return {
        response: 'ç”³ã—è¨³ã”ã–ã„ã¾ã›ã‚“ãŒã€ç¾åœ¨AIã‚µãƒ¼ãƒ“ã‚¹ã«å•é¡ŒãŒç™ºç”Ÿã—ã¦ã„ã¾ã™ã€‚ã—ã°ã‚‰ãæ™‚é–“ã‚’ãŠã„ã¦ã‹ã‚‰å†åº¦ãŠè©¦ã—ãã ã•ã„ã€‚',
        confidence: 0,
        sources: [],
        suggestedActions: ['å¾Œã§ã‚‚ã†ä¸€åº¦è©¦ã—ã¦ãã ã•ã„', 'ç®¡ç†è€…ã«ãŠå•ã„åˆã‚ã›ãã ã•ã„']
      };
    }
  }

  async findExpertsBySkill(skill: string): Promise<AIResponse> {
    try {
      const profiles = await this.profileRepository.findByExpertise(skill);
      
      if (profiles.length === 0) {
        return {
          response: `ã€Œ${skill}ã€ã®ã‚¹ã‚­ãƒ«ã‚’æŒã¤ãƒ¡ãƒ³ãƒãƒ¼ã¯è¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\nãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãŒæœªè¨­å®šã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚ãƒ¡ãƒ³ãƒãƒ¼ã«ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ä½œæˆã‚’ä¿ƒã—ã¦ã¿ã¦ãã ã•ã„ã€‚`,
          confidence: 0.8,
          suggestedActions: [
            'ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ä½œæˆã‚’ä¿ƒã™',
            'åˆ¥ã®ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã§æ¤œç´¢ã™ã‚‹',
            'ç›´æ¥ãƒ¡ãƒ³ãƒãƒ¼ã«èã„ã¦ã¿ã‚‹'
          ]
        };
      }

      let response = `ã€Œ${skill}ã€ã®ã‚¹ã‚­ãƒ«ã‚’æŒã¤ãƒ¡ãƒ³ãƒãƒ¼ã‚’è¦‹ã¤ã‘ã¾ã—ãŸï¼š\n\n`;
      
      profiles.forEach((profile: any, index: number) => {
        const user = profile.users || {};
        response += `${index + 1}. **${user.name || 'Unknown User'}**\n`;
        
        if (profile.workStyle) {
          response += `   åƒãæ–¹: ${profile.workStyle}\n`;
        }
        
        if (profile.communicationStyle) {
          response += `   ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³: ${profile.communicationStyle}\n`;
        }
        
        if (profile.availability) {
          response += `   å¯¾å¿œå¯èƒ½æ™‚é–“: ${profile.availability}\n`;
        }
        
        response += '\n';
      });

      response += `ğŸ’¡ ã“ã‚Œã‚‰ã®ãƒ¡ãƒ³ãƒãƒ¼ã«ç›´æ¥é€£çµ¡ã‚’å–ã£ã¦ã¿ã¦ãã ã•ã„ã€‚`;

      return {
        response,
        confidence: 0.9,
        sources: profiles.map((p: any) => p.users?.name || 'Unknown User'),
        suggestedActions: [
          'ãƒ¡ãƒ³ãƒãƒ¼ã«ç›´æ¥ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’é€ã‚‹',
          'é–¢é€£ã™ã‚‹ãƒãƒ£ãƒ³ãƒãƒ«ã§è³ªå•ã™ã‚‹'
        ]
      };
    } catch (error) {
      logger.error('Error finding experts by skill:', error);
      throw error;
    }
  }

  async getUserExpertise(userName: string): Promise<AIResponse> {
    try {
      // Find user by name (fuzzy matching)
      const users = await this.userRepository.findAll();
      const user = users.find(u => 
        u.name.toLowerCase().includes(userName.toLowerCase()) ||
        userName.toLowerCase().includes(u.name.toLowerCase())
      );

      if (!user) {
        return {
          response: `ã€Œ${userName}ã€ã•ã‚“ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸã€‚\n\næ­£ç¢ºãªåå‰ã§å†åº¦æ¤œç´¢ã—ã¦ã¿ã¦ãã ã•ã„ã€‚`,
          confidence: 0.3,
          suggestedActions: [
            'æ­£ç¢ºãªåå‰ã§æ¤œç´¢ã™ã‚‹',
            'ãƒ¡ãƒ³ãƒãƒ¼ä¸€è¦§ã‚’ç¢ºèªã™ã‚‹'
          ]
        };
      }

      const profile = await this.profileRepository.findByUserId(user.id);
      const recentResponses = await this.shuffleResponseRepository.findByUserId(user.id, 5);

      let response = `**${user.name}ã•ã‚“ã®æƒ…å ±**\n\n`;

      if (profile) {
        if (profile.expertise && profile.expertise.length > 0) {
          response += `**å°‚é–€åˆ†é‡:**\n`;
          profile.expertise.forEach(skill => {
            response += `â€¢ ${skill}\n`;
          });
          response += '\n';
        }

        if (profile.workStyle) {
          response += `**åƒãæ–¹ã‚¹ã‚¿ã‚¤ãƒ«:** ${profile.workStyle}\n`;
        }

        if (profile.communicationStyle) {
          response += `**ã‚³ãƒŸãƒ¥ãƒ‹ã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚¹ã‚¿ã‚¤ãƒ«:** ${profile.communicationStyle}\n`;
        }

        if (profile.availability) {
          response += `**å¯¾å¿œå¯èƒ½æ™‚é–“:** ${profile.availability}\n`;
        }
      } else {
        response += `ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“ã€‚\n`;
      }

      if (recentResponses.length > 0) {
        response += `\n**æœ€è¿‘ã®çŸ¥è­˜å…±æœ‰:**\n`;
        recentResponses.slice(0, 3).forEach((resp: any, index: number) => {
          const question = resp.questions?.content || 'è³ªå•ä¸æ˜';
          const answer = resp.response.length > 100 ? 
            resp.response.substring(0, 97) + '...' : resp.response;
          response += `${index + 1}. ${question}\n   â†’ ${answer}\n\n`;
        });
      }

      const confidence = profile ? 0.9 : 0.5;
      const sources = profile ? [user.name] : [];

      return {
        response,
        confidence,
        sources,
        suggestedActions: [
          `${user.name}ã•ã‚“ã«ç›´æ¥é€£çµ¡ã™ã‚‹`,
          profile ? 'è©³ç´°ãªãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ã‚’ç¢ºèªã™ã‚‹' : 'ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«ä½œæˆã‚’ä¿ƒã™'
        ]
      };
    } catch (error) {
      logger.error('Error getting user expertise:', error);
      throw error;
    }
  }

  async getGeneralKnowledgeAnswer(question: string): Promise<AIResponse> {
    try {
      // Search for relevant knowledge from shuffle responses
      const recentResponses = await this.shuffleResponseRepository.findRecentResponses(20);
      
      // Build context from existing knowledge
      const knowledgeContext = recentResponses
        .map((resp: any) => `Q: ${resp.questions?.content || 'è³ªå•ä¸æ˜'}\nA: ${resp.response}`)
        .join('\n\n');

      const systemPrompt = `ã‚ãªãŸã¯çµ„ç¹”å†…ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒãƒ–ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®çµ„ç¹”å†…ã®çŸ¥è­˜ã‚’å‚è€ƒã«ã—ã¦ã€è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

çµ„ç¹”å†…ã®æ—¢å­˜çŸ¥è­˜:
${knowledgeContext}

å›ç­”ã®éš›ã¯ï¼š
1. çµ„ç¹”å†…ã®æ—¢å­˜çŸ¥è­˜ã‚’å„ªå…ˆã—ã¦æ´»ç”¨ã™ã‚‹
2. å…·ä½“çš„ã§å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã™ã‚‹
3. æ—¥æœ¬èªã§è‡ªç„¶ã«å›ç­”ã™ã‚‹
4. ä¸æ˜ãªç‚¹ã¯ç´ ç›´ã«ã€Œã‚ã‹ã‚‰ãªã„ã€ã¨ç­”ãˆã‚‹
5. å¿…è¦ã«å¿œã˜ã¦é–¢é€£ã™ã‚‹ãƒ¡ãƒ³ãƒãƒ¼ã‚„æƒ…å ±æºã‚’ææ¡ˆã™ã‚‹`;

      const completion = await this.openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'system',
            content: systemPrompt
          },
          {
            role: 'user',
            content: question
          }
        ],
        max_tokens: 400,
        temperature: 0.7,
      });

      const response = completion.choices[0]?.message?.content || 'ã™ã¿ã¾ã›ã‚“ã€å›ç­”ã‚’ç”Ÿæˆã§ãã¾ã›ã‚“ã§ã—ãŸã€‚';
      
      return {
        response,
        confidence: 0.7,
        sources: ['çµ„ç¹”å†…ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹'],
        suggestedActions: [
          'é–¢é€£ã™ã‚‹ãƒ¡ãƒ³ãƒãƒ¼ã«ç›´æ¥è³ªå•ã™ã‚‹',
          'ã‚ˆã‚Šå…·ä½“çš„ãªè³ªå•ã‚’ã™ã‚‹',
          'é–¢é€£ãƒãƒ£ãƒ³ãƒãƒ«ã§è­°è«–ã™ã‚‹'
        ]
      };
    } catch (error) {
      logger.error('Error getting general knowledge answer:', error);
      throw error;
    }
  }

  private async buildKnowledgeContext(query: AIQuery): Promise<KnowledgeContext> {
    try {
      const [profiles, recentResponses, users] = await Promise.all([
        this.profileRepository.findAll(),
        this.shuffleResponseRepository.findRecentResponses(10),
        this.userRepository.findAll()
      ]);

      return {
        profiles,
        recentResponses,
        users
      };
    } catch (error) {
      logger.error('Error building knowledge context:', error);
      return {
        profiles: [],
        recentResponses: [],
        users: []
      };
    }
  }

  private buildSystemPrompt(context: KnowledgeContext): string {
    const userCount = context.users.length;
    const profileCount = context.profiles.length;
    const responseCount = context.recentResponses.length;

    return `ã‚ãªãŸã¯çµ„ç¹”å†…ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒãƒ–ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®æƒ…å ±ã‚’æ´»ç”¨ã—ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

çµ„ç¹”æƒ…å ±:
- ç·ãƒ¡ãƒ³ãƒãƒ¼æ•°: ${userCount}å
- ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«è¨­å®šæ¸ˆã¿: ${profileCount}å
- æœ€è¿‘ã®çŸ¥è­˜å…±æœ‰: ${responseCount}ä»¶

ã‚ãªãŸã®å½¹å‰²:
1. ãƒ¡ãƒ³ãƒãƒ¼ã®ã‚¹ã‚­ãƒ«ã‚„å°‚é–€åˆ†é‡ã«é–¢ã™ã‚‹è³ªå•ã«ç­”ãˆã‚‹
2. é©åˆ‡ãªãƒ¡ãƒ³ãƒãƒ¼ã‚’ç´¹ä»‹ã™ã‚‹
3. çµ„ç¹”å†…ã®çŸ¥è­˜ã‚’æ´»ç”¨ã—ã¦å®Ÿç”¨çš„ãªã‚¢ãƒ‰ãƒã‚¤ã‚¹ã‚’æä¾›ã™ã‚‹
4. æ—¥æœ¬èªã§è‡ªç„¶ã‹ã¤è¦ªã—ã¿ã‚„ã™ãå›ç­”ã™ã‚‹

å›ç­”ã®éš›ã¯ï¼š
- å…·ä½“çš„ã§å®Ÿç”¨çš„ãªæƒ…å ±ã‚’æä¾›ã™ã‚‹
- ä¸æ˜ãªç‚¹ã¯ç´ ç›´ã«ã€Œã‚ã‹ã‚‰ãªã„ã€ã¨ç­”ãˆã‚‹
- å¿…è¦ã«å¿œã˜ã¦é–¢é€£ã™ã‚‹ãƒ¡ãƒ³ãƒãƒ¼ã‚„æƒ…å ±æºã‚’ææ¡ˆã™ã‚‹
- çµ„ç¹”å†…ã®ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¿ƒé€²ã™ã‚‹
- ç°¡æ½”ã§èª­ã¿ã‚„ã™ã„å½¢å¼ã§å›ç­”ã™ã‚‹`;
  }

  private parseAIResponse(response: string, context: KnowledgeContext): AIResponse {
    // Simple confidence calculation based on response characteristics
    let confidence = 0.7;
    
    if (response.includes('ã‚ã‹ã‚‰ãªã„') || response.includes('ä¸æ˜')) {
      confidence = 0.3;
    } else if (response.includes('è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ') || response.includes('ä»¥ä¸‹ã®')) {
      confidence = 0.9;
    }

    // Extract potential sources from context
    const sources: string[] = [];
    if (context.profiles.length > 0) {
      sources.push('ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±');
    }
    if (context.recentResponses.length > 0) {
      sources.push('æœ€è¿‘ã®çŸ¥è­˜å…±æœ‰');
    }

    // Generate suggested actions
    const suggestedActions = [
      'é–¢é€£ã™ã‚‹ãƒ¡ãƒ³ãƒãƒ¼ã«ç›´æ¥é€£çµ¡ã™ã‚‹',
      'ã‚ˆã‚Šè©³ç´°ãªæƒ…å ±ã‚’æ±‚ã‚ã‚‹',
      'é–¢é€£ãƒãƒ£ãƒ³ãƒãƒ«ã§è­°è«–ã™ã‚‹'
    ];

    return {
      response,
      confidence,
      sources,
      suggestedActions
    };
  }

  async testConnection(): Promise<boolean> {
    try {
      const completion = await this.openai.chat.completions.create({
        model: 'gpt-3.5-turbo',
        messages: [
          {
            role: 'user',
            content: 'Hello, this is a test message.'
          }
        ],
        max_tokens: 10,
      });

      return completion.choices.length > 0;
    } catch (error) {
      logger.error('OpenAI connection test failed:', error);
      return false;
    }
  }

  private buildEnhancedSystemPrompt(aiContext: any): string {
    const { userContext, organizationContext, knowledgeContext, conversationContext } = aiContext;

    return `ã‚ãªãŸã¯çµ„ç¹”å†…ã®ãƒŠãƒ¬ãƒƒã‚¸ãƒãƒ–ã‚¢ã‚·ã‚¹ã‚¿ãƒ³ãƒˆã§ã™ã€‚ä»¥ä¸‹ã®è±Šå¯Œãªæƒ…å ±ã‚’æ´»ç”¨ã—ã¦è³ªå•ã«ç­”ãˆã¦ãã ã•ã„ã€‚

## çµ„ç¹”æƒ…å ±
- ç·ãƒ¡ãƒ³ãƒãƒ¼æ•°: ${organizationContext.totalUsers}å
- ã‚¢ã‚¯ãƒ†ã‚£ãƒ–ãƒ¦ãƒ¼ã‚¶ãƒ¼: ${organizationContext.activeUsers}å
- éƒ¨ç½²: ${organizationContext.departments.join(', ')}
- ä¸»è¦ã‚¹ã‚­ãƒ«: ${organizationContext.commonSkills.slice(0, 5).join(', ')}

## è³ªå•è€…æƒ…å ±
- åå‰: ${userContext.userName}
- éƒ¨ç½²: ${userContext.department || 'æœªè¨­å®š'}
- å½¹è·: ${userContext.role || 'æœªè¨­å®š'}
- å°‚é–€åˆ†é‡: ${userContext.expertise.join(', ') || 'æœªè¨­å®š'}

## é–¢é€£çŸ¥è­˜
- é–¢é€£ã™ã‚‹çŸ¥è­˜é …ç›®: ${knowledgeContext.relevantKnowledge.length}ä»¶
- é–¢é€£ãƒ¦ãƒ¼ã‚¶ãƒ¼: ${knowledgeContext.relatedUsers.length}å
- æ¨å¥¨ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆ: ${knowledgeContext.suggestedExperts.length}å
- çŸ¥è­˜ã‚®ãƒ£ãƒƒãƒ—: ${knowledgeContext.knowledgeGaps.join(', ') || 'ãªã—'}

## ä¼šè©±ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ
- è³ªå•ã‚¿ã‚¤ãƒ—: ${conversationContext.queryType}
- ä¿¡é ¼åº¦: ${Math.round(conversationContext.confidence * 100)}%

## æœ€è¿‘ã®ãƒˆãƒ¬ãƒ³ãƒ‰
${organizationContext.recentTrends.slice(0, 3).map(trend => 
  `- ${trend.topic}: ${trend.trend} (${trend.frequency}å›è¨€åŠ)`
).join('\n')}

ã‚ãªãŸã®å½¹å‰²:
1. ä¸Šè¨˜ã®è±Šå¯Œãªæƒ…å ±ã‚’æ´»ç”¨ã—ã¦ã€å…·ä½“çš„ã§å®Ÿç”¨çš„ãªå›ç­”ã‚’æä¾›ã™ã‚‹
2. é©åˆ‡ãªãƒ¡ãƒ³ãƒãƒ¼ã‚’ç´¹ä»‹ã—ã€ã‚³ãƒ©ãƒœãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’ä¿ƒé€²ã™ã‚‹
3. çŸ¥è­˜ã‚®ãƒ£ãƒƒãƒ—ãŒã‚ã‚‹å ´åˆã¯ã€ãã‚Œã‚’æ˜ç¤ºã—æ”¹å–„ã‚’ææ¡ˆã™ã‚‹
4. æ—¥æœ¬èªã§è‡ªç„¶ã‹ã¤è¦ªã—ã¿ã‚„ã™ãå›ç­”ã™ã‚‹
5. çµ„ç¹”ã®çŸ¥è­˜å…±æœ‰æ–‡åŒ–ã‚’ä¿ƒé€²ã™ã‚‹

å›ç­”ã®éš›ã¯ï¼š
- é–¢é€£ã™ã‚‹çŸ¥è­˜é …ç›®ã‚„å°‚é–€å®¶ã‚’å…·ä½“çš„ã«ç´¹ä»‹ã™ã‚‹
- ä¸æ˜ãªç‚¹ã¯ç´ ç›´ã«ã€Œã‚ã‹ã‚‰ãªã„ã€ã¨ç­”ãˆã‚‹
- çµ„ç¹”å†…ã®ãƒªã‚½ãƒ¼ã‚¹ã‚’æœ€å¤§é™æ´»ç”¨ã™ã‚‹ææ¡ˆã‚’ã™ã‚‹
- ç°¡æ½”ã§èª­ã¿ã‚„ã™ã„å½¢å¼ã§å›ç­”ã™ã‚‹`;
  }

  private buildKnowledgeContextFromAI(aiContext: any): KnowledgeContext {
    const { knowledgeContext, organizationContext } = aiContext;
    
    return {
      profiles: [], // Legacy field for compatibility
      recentResponses: [], // Legacy field for compatibility
      users: [], // Legacy field for compatibility
      relevantKnowledge: knowledgeContext.relevantKnowledge,
      relatedUsers: knowledgeContext.relatedUsers,
      suggestedExperts: knowledgeContext.suggestedExperts,
      knowledgeGaps: knowledgeContext.knowledgeGaps,
      organizationTrends: organizationContext.recentTrends
    };
  }

  private parseEnhancedAIResponse(response: string, aiContext: any): AIResponse {
    const { conversationContext, knowledgeContext } = aiContext;
    
    // Use conversation context confidence as base
    let confidence = conversationContext.confidence;
    
    // Adjust confidence based on response characteristics
    if (response.includes('ã‚ã‹ã‚‰ãªã„') || response.includes('ä¸æ˜')) {
      confidence *= 0.5;
    } else if (response.includes('è¦‹ã¤ã‹ã‚Šã¾ã—ãŸ') || response.includes('ä»¥ä¸‹ã®')) {
      confidence = Math.min(confidence * 1.2, 1.0);
    }

    // Extract sources from knowledge context
    const sources: string[] = [];
    if (knowledgeContext.relevantKnowledge.length > 0) {
      sources.push(`é–¢é€£çŸ¥è­˜ (${knowledgeContext.relevantKnowledge.length}ä»¶)`);
    }
    if (knowledgeContext.suggestedExperts.length > 0) {
      sources.push(`ã‚¨ã‚­ã‚¹ãƒ‘ãƒ¼ãƒˆæƒ…å ± (${knowledgeContext.suggestedExperts.length}å)`);
    }
    if (knowledgeContext.relatedUsers.length > 0) {
      sources.push(`é–¢é€£ãƒ¦ãƒ¼ã‚¶ãƒ¼ (${knowledgeContext.relatedUsers.length}å)`);
    }

    // Use conversation context suggested follow-ups or generate new ones
    const suggestedActions = conversationContext.suggestedFollowUps.length > 0 
      ? conversationContext.suggestedFollowUps
      : this.generateContextualActions(aiContext);

    return {
      response,
      confidence,
      sources,
      suggestedActions
    };
  }

  private generateContextualActions(aiContext: any): string[] {
    const { knowledgeContext, conversationContext } = aiContext;
    const actions: string[] = [];

    // Add expert-specific actions
    if (knowledgeContext.suggestedExperts.length > 0) {
      const topExpert = knowledgeContext.suggestedExperts[0];
      actions.push(`${topExpert.userName}ã•ã‚“ã«ç›´æ¥ç›¸è«‡ã™ã‚‹`);
    }

    // Add knowledge gap actions
    if (knowledgeContext.knowledgeGaps.length > 0) {
      actions.push('ã“ã®åˆ†é‡ã®çŸ¥è­˜å…±æœ‰ã‚’ä¿ƒé€²ã™ã‚‹');
    }

    // Add related user actions
    if (knowledgeContext.relatedUsers.length > 0) {
      actions.push('é–¢é€£ã™ã‚‹çµŒé¨“ã‚’æŒã¤ãƒ¡ãƒ³ãƒãƒ¼ã¨æƒ…å ±äº¤æ›ã™ã‚‹');
    }

    // Add query-type specific actions
    switch (conversationContext.queryType) {
      case 'skill_search':
        actions.push('ã‚¹ã‚­ãƒ«ãƒãƒƒãƒ—ã‚’æ›´æ–°ã™ã‚‹');
        break;
      case 'user_inquiry':
        actions.push('ãƒ—ãƒ­ãƒ•ã‚£ãƒ¼ãƒ«æƒ…å ±ã‚’å……å®Ÿã•ã›ã‚‹');
        break;
      case 'knowledge_request':
        actions.push('ãƒŠãƒ¬ãƒƒã‚¸ãƒ™ãƒ¼ã‚¹ã«æƒ…å ±ã‚’è¿½åŠ ã™ã‚‹');
        break;
    }

    return actions.slice(0, 3); // Limit to 3 actions
  }

  async extractAndIndexKnowledge(): Promise<void> {
    try {
      logger.info('Starting knowledge extraction and indexing');
      
      const extractionResult = await this.knowledgeExtractor.extractAllKnowledge();
      
      logger.info('Knowledge extraction completed', {
        totalItems: extractionResult.knowledgeItems.length,
        newItems: extractionResult.newItemsFound,
        processingTime: extractionResult.processingTime
      });
      
      // In a production system, you would store this in a vector database
      // or search index for faster retrieval
    } catch (error) {
      logger.error('Error in knowledge extraction and indexing:', error);
      throw error;
    }
  }

  async getKnowledgeInsights(): Promise<{
    totalKnowledgeItems: number;
    topSkills: string[];
    activeContributors: string[];
    knowledgeGaps: string[];
    recentTrends: any[];
  }> {
    try {
      const extractionResult = await this.knowledgeExtractor.extractAllKnowledge();
      const knowledgeGraph = await this.knowledgeExtractor.buildKnowledgeGraph(extractionResult.knowledgeItems);
      
      // Analyze skills
      const skillNodes = knowledgeGraph.nodes.filter(node => node.type === 'skill');
      const topSkills = skillNodes
        .sort((a, b) => (b.properties.mentionCount || 0) - (a.properties.mentionCount || 0))
        .slice(0, 10)
        .map(node => node.label);

      // Find active contributors
      const userContributions = new Map<string, number>();
      extractionResult.knowledgeItems.forEach(item => {
        userContributions.set(item.userName, (userContributions.get(item.userName) || 0) + 1);
      });
      
      const activeContributors = Array.from(userContributions.entries())
        .sort(([,a], [,b]) => b - a)
        .slice(0, 5)
        .map(([name]) => name);

      // Identify knowledge gaps (simplified)
      const knowledgeGaps = [
        'æœ€æ–°æŠ€è¡“æƒ…å ±ã®ä¸è¶³',
        'ãƒ—ãƒ­ã‚»ã‚¹æ”¹å–„ã®äº‹ä¾‹ä¸è¶³',
        'ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°æƒ…å ±ã®ä¸è¶³'
      ];

      // Get recent trends
      const organizationContext = await this.contextBuilder.buildOrganizationContext();

      return {
        totalKnowledgeItems: extractionResult.knowledgeItems.length,
        topSkills,
        activeContributors,
        knowledgeGaps,
        recentTrends: organizationContext.recentTrends
      };
    } catch (error) {
      logger.error('Error getting knowledge insights:', error);
      throw error;
    }
  }
}